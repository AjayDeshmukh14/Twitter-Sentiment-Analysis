{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1- Sentiment Analysis for word 'Trump'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Contents of Extracted file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Trump.txt\") as f:\n",
    "    tweet= f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "For cleaning the data we have used the Regex library, while cleaning we first remove the URL's, then we remove the usernames starting with '@', after that we remove special characters and string 'RT' followed by two white spaces that denotes a retweet. It is also important to change the case of all the given words to lower case as python is case sensitive and all the words in the positive, negative and stop word list are in lower case. At last store different words as different elements of a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#remove links from file\n",
    "tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "#remove usernames from file\n",
    "tweet = re.sub(r\"@\\S+\", \"\", tweet)\n",
    "#remove special characters \n",
    "tweet = re.sub('[?!@#$%^&*()_+-\\;–./\\'’|‘]','', tweet)\n",
    "#remove 'RT  '\n",
    "tweet=tweet.replace('RT  ','')\n",
    "#convert to lower format\n",
    "tweet=tweet.lower()\n",
    "#save words in a list\n",
    "tweets=tweet.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open and Read the files containing Positive, Negative and Stop words \n",
    "We have opened the positive, negative and stop words files to read data and store the positive words in pword list, negative words in nword list and stop words in sword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"positive.txt\") as p:\n",
    "    pwords= p.read().split()\n",
    "\n",
    "with open(\"negative.txt\") as n:\n",
    "    nwords= n.read().split()\n",
    "    \n",
    "with open(\"Stop word.txt\") as s:\n",
    "    swords= s.read().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of Positive, Negative, Stop words and other words\n",
    "We count the number of posititve words by comparing each word in the document with the list of positive words and updating the count for each matching instance. Similarly we calculate the value of the count of negative and stop words, the remaining words are counted in the 'other word' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word count for the extracted document is 30007\n",
      "The word count for the positive words in the document is 1728\n",
      "The ratio of positive words to the whole word count is 0.0576\n",
      "The word count for the negative words in the document is 1207\n",
      "The ratio of negative words to the whole word count is 0.0402\n",
      "The word count for the stop words in the document is 11395\n",
      "The ratio of stop words to the whole word count is 0.3797\n",
      "The word count for other words in the document is 15677\n",
      "The ratio of other words to the whole word count is 0.5224\n"
     ]
    }
   ],
   "source": [
    "word_count=len(tweets)\n",
    "print(\"The word count for the extracted document is \"+ str(word_count))\n",
    "\n",
    "pcount=0\n",
    "ncount=0\n",
    "scount=0\n",
    "for i in tweets:\n",
    "    if i in pwords :\n",
    "        pcount=pcount+1\n",
    "    elif i in nwords:\n",
    "        ncount=ncount+1\n",
    "    elif i in swords:\n",
    "        scount=scount+1\n",
    "        \n",
    "print(\"The word count for the positive words in the document is \"+ str(pcount))\n",
    "print(\"The ratio of positive words to the whole word count is \" +str(round(pcount/word_count,4)))\n",
    "\n",
    "\n",
    "print(\"The word count for the negative words in the document is \"+ str(ncount))\n",
    "print(\"The ratio of negative words to the whole word count is \" +str(round(ncount/word_count,4)))\n",
    "\n",
    "        \n",
    "print(\"The word count for the stop words in the document is \"+ str(scount))\n",
    "print(\"The ratio of stop words to the whole word count is \" +str(round(scount/word_count,4)))\n",
    "\n",
    "other_word_count= word_count-(pcount+ncount+scount)\n",
    "print(\"The word count for other words in the document is \"+ str(other_word_count))\n",
    "print(\"The ratio of other words to the whole word count is \" +str(round(other_word_count/word_count,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the Sentiment for the keyword 'Trump'.\n",
    "The value for the sentiment for the word can be determined by calculating the difference between the positive and negetive word count in the document. Thus we assign a value of +1 to all the positive words in the document and -1 to all the negative words in the document. To determine the intenisty of the we caluculate the percentage of positive and negative tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value for positive sentiment will be 1728\n",
      "Value for negative sentiment will be -1207\n",
      "Value for sentiment for the word 'Trump' will be 521\n",
      "Percentage of positive words 58.8756\n",
      "Percentage of negative words 41.1244\n"
     ]
    }
   ],
   "source": [
    "print(\"Value for positive sentiment will be \" +str(pcount))\n",
    "print(\"Value for negative sentiment will be \" +str(-ncount))\n",
    "print(\"Value for sentiment for the word \\'Trump\\' will be \" +str(pcount-ncount))\n",
    "print(\"Percentage of positive words \" +str(round(pcount*100/(pcount+ncount),4)))\n",
    "print(\"Percentage of negative words \" +str(round(ncount*100/(pcount+ncount),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The positive value in the sentiment indicate that the sentiment for the word 'Trump' is positive, the difference between the  percentage of negative and positive words is not large, thus the overall sentiment for the word 'Trump' can be said to be* **'Weakly Positive'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2- Sentiment Analysis for word 'Lion King' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Contents of Extracted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Lion King.txt\") as flk:\n",
    "    tweetlk= flk.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "For cleaning the data we have used the Regex library, while cleaning we first remove the URL's, then we remove the usernames starting with '@', after that we remove special characters and string 'RT' followed by two white spaces that denotes a retweet.  It is also important to change the case of all the given words to lower case as python is case sensitive and all the words in the positive, negative and stop word list are in lower case. At last store different words as different elements of a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove links from file\n",
    "tweetlk = re.sub(r\"http\\S+\", \"\", tweetlk)\n",
    "#remove usernames from file\n",
    "tweetlk = re.sub(r\"@\\S+\", \"\", tweetlk)\n",
    "#remove special characters \n",
    "tweetlk = re.sub('[?!@#$%^&*()_+-\\;–./\\'’|‘]','', tweetlk)\n",
    "#remove 'RT  '\n",
    "tweetlk = tweetlk.replace('RT  ','')\n",
    "#convert to lower format\n",
    "tweetlk=tweetlk.lower()\n",
    "#save words in a list\n",
    "tweetslk=tweetlk.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open and Read the files containing Positive, Negative and Stop words \n",
    "We have opened the positive, negative and stop words files to read data and store the positive words in pword list, negative words in nword list and stop words in sword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"positive.txt\") as p:\n",
    "    pwords= p.read().split()\n",
    "\n",
    "with open(\"negative.txt\") as n:\n",
    "    nwords= n.read().split()\n",
    "    \n",
    "with open(\"Stop word.txt\") as s:\n",
    "    swords= s.read().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of Positive, Negative, Stop words and other words\n",
    "We count the number of posititve words by comparing each word in the document with the list of positive words and updating the count for each matching instance. Similarly we calculate the value of the count of negative and stop words, the remaining words are counted in the 'other word' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word count for the extracted document is 18358\n",
      "The word count for the positive words in the document is 930\n",
      "The ratio of positive words to the whole word count is 0.0507\n",
      "The word count for the negative words in the document is 296\n",
      "The ratio of negative words to the whole word count is 0.0161\n",
      "The word count for the stop words in the document is 6854\n",
      "The ratio of stop words to the whole word count is 0.3734\n",
      "The word count for other words in the document is 10278\n",
      "The ratio of other words to the whole word count is 0.5599\n"
     ]
    }
   ],
   "source": [
    "word_countlk=len(tweetslk)\n",
    "print(\"The word count for the extracted document is \"+ str(word_countlk))\n",
    "\n",
    "pcountlk=0\n",
    "ncountlk=0\n",
    "scountlk=0\n",
    "for i in tweetslk:\n",
    "    if i in pwords :\n",
    "        pcountlk=pcountlk+1\n",
    "    elif i in nwords:\n",
    "        ncountlk=ncountlk+1\n",
    "    elif i in swords:\n",
    "        scountlk=scountlk+1\n",
    "\n",
    "print(\"The word count for the positive words in the document is \"+ str(pcountlk))\n",
    "print(\"The ratio of positive words to the whole word count is \" +str(round(pcountlk/word_countlk,4)))\n",
    "\n",
    "print(\"The word count for the negative words in the document is \"+ str(ncountlk))\n",
    "print(\"The ratio of negative words to the whole word count is \" +str(round(ncountlk/word_countlk,4)))\n",
    "\n",
    "\n",
    "print(\"The word count for the stop words in the document is \"+ str(scountlk))\n",
    "print(\"The ratio of stop words to the whole word count is \" +str(round(scountlk/word_countlk,4)))\n",
    "\n",
    "other_word_countlk= word_countlk-(pcountlk+ncountlk+scountlk)\n",
    "print(\"The word count for other words in the document is \"+ str(other_word_countlk))\n",
    "print(\"The ratio of other words to the whole word count is \" +str(round(other_word_countlk/word_countlk,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the Sentiment for the keyword 'Lion King'.\n",
    "The value for the sentiment for the word can be determined by calculating the difference between the positive and negetive word count in the document. Thus we assign a value of +1 to all the positive words in the document and -1 to all the negative words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value for positive sentiment will be 930\n",
      "Value for negative sentiment will be -296\n",
      "Value for sentiment for the word 'Lion King' will be 634\n",
      "Percentage of positive words 75.8564\n",
      "Percentage of negative words 24.1436\n"
     ]
    }
   ],
   "source": [
    "print(\"Value for positive sentiment will be \" +str(pcountlk))\n",
    "print(\"Value for negative sentiment will be \" +str(-ncountlk))\n",
    "print(\"Value for sentiment for the word \\'Lion King\\' will be \" +str(pcountlk-ncountlk))\n",
    "print(\"Percentage of positive words \" +str(round(pcountlk*100/(pcountlk+ncountlk),4)))\n",
    "print(\"Percentage of negative words \" +str(round(ncountlk*100/(pcountlk+ncountlk),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The positive value in the sentiment indicate that the sentiment for the word 'Lion King' is positive, the difference between the  percentage of negative and positive words is significant, thus the overall sentiment for the keyword 'Lion King' can be said to be* **'Strongly Positive'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://stackoverflow.com/questions/24399820/expression-to-remove-url-links-from-twitter-tweet/24399874\n",
    "2. https://docs.python.org/3/library/re.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
